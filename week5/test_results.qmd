---
title: "Test Results"
format: html
editor: visual
---

#### Load Libraries

```{r, message=FALSE}
library(tidyverse)
library(janitor)
library(vembedr)
```

#### The Story

You test positive for a rare disease that only effects 0.001 (One in one thousand people).

So you ask the doctor:

-   How certain is it that I have this disease?

    -   The test correctly identifies 99% of people that have the disease and only incorrectly identifies 1% of people that don't have the disease

What are the chances that you actually have this disease?

-   Some would say 99%, the accuracy of the test

    -   What does bayes say?

$$
P(B \mid A) = \frac{P(B) L(B \mid A)}{P(A)} 
$$

B \<- Has Disease

A \<- Positive test result

P(B\|A) - The probability of having the disease given a positive test result

#### Simulate the Data

```{r}

set.seed(70)  # For reproducibility

# Parameters
n_patients <- 10000  # Total population size
n_diseased <- 10     # Number of patients with the disease
sensitivity <- 0.99  # True positive rate (sensitivity)
false_positive_rate <- 0.01  # False positive rate

# Step 1: Create the DataFrame with patients
patients <- data.frame(
  patient_id = 1:n_patients,
  has_disease = c(rep(1, n_diseased), rep(0, n_patients - n_diseased))  # 10 with the disease, rest without
)

# Shuffle the DataFrame to randomize patient order
patients <- patients %>%
  sample_frac(size = 1)

# Step 2: Simulate the test results based on disease status
patients <- patients %>%
  mutate(
    # Test result is positive if the person has the disease and the test is sensitive,
    # or if they don't have the disease but it's a false positive
    test_result = case_when(
      has_disease == 1 & rbinom(n_patients, size = 1, prob = sensitivity) == 1 ~ "positive",
      has_disease == 0 & rbinom(n_patients, size = 1, prob = false_positive_rate) == 1 ~ "positive",
      TRUE ~ "negative"
    )
  )




```

#### Apply Bayes Theorem in Class

1.  Determine the prior probability that someone has rare disease (has_disease)

-   P(B)

```{r}
patients %>% 
  tabyl(has_disease)
```

```{r}
probability_has_disease <- 0.001
```

2.  Determine the prior probability that someone tests positive for rare disease (test_result)
    -   P(A)

```{r}
patients %>% 
  tabyl(test_result)
```

```{r}
probability_positive_test_result <- 0.0112
```

3.  Determine the likelihood of being disease positive, given that has disease
    -   L(B\|A) = P(A\|B)

```{r}
patients %>% 
  tabyl(test_result, has_disease) %>% 
  adorn_percentages("col")
```

3.  Determine posterior probability via bayes theorem
    -   P(B\|A)

```{r}
patients %>% 
  tabyl(has_disease, test_result) %>% 
  adorn_percentages("col") 
```

#### Video

```{r}
embed_url("https://www.youtube.com/watch?v=R13BD8qKeTg")
```

#### What about two positive test results?

-   In my opinion, if we were to conduct the same test a second time, we would have a second prior probability. A follow-up test, given a positive initial result, is a proper step, one that verifies the initial results. Yet, a positive outcome of the same test confirms the need for additional, different tests. In the end, multiple priors analyzed with data acquired from additional testing, or assays, strengthens the post probability.

$$
P(\text{have disease} \mid \text{positive second test}) = \frac{P(\text{have disease after first positive}) \cdot P(\text{positive second test} \mid \text{have disease})}{P(\text{positive second test})}
$$
